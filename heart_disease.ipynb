{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the Heart Disease Prediction notebook! In this session, we will explore a dataset related to heart disease and build a machine learning model to predict the likelihood of a patient having heart disease. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset Exploration and Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our journey, let's gain a thorough understanding of the dataset. We are dealing with a dataset that comprises 14 attributes, each providing valuable insights into a patient's health. From the patient's age and gender to specific medical indicators such as blood pressure and cholesterol levels, these attributes collectively form the basis for predicting heart disease."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.1 Variable Information\n",
    "\n",
    "Before diving into the analysis, let's understand the variables in our dataset:\n",
    "\n",
    "1. Age (age): Patient's age in years.\n",
    "\n",
    "2. Sex (sex): Gender of the patient.\n",
    "    Values: 1 = Male, 0 = Female\n",
    "\n",
    "3. Chest Pain Type (cp): Type of chest pain experienced.\n",
    "    Values: 1 = Typical angina, 2 = Atypical angina, 3 = Non-anginal pain, 4 = Asymptomatic\n",
    "\n",
    "4. Resting Blood Pressure (trestbps): Blood pressure on admission in mm Hg.\n",
    "\n",
    "5. Serum Cholesterol (chol): Serum cholesterol level in mg/dl.\n",
    "\n",
    "6. Fasting Blood Sugar (fbs): Fasting blood sugar level.\n",
    "    Values: 1 = >120 mg/dl, 0 = <=120 mg/dl\n",
    "\n",
    "7. Resting Electrocardiographic Results (restecg): Results of resting electrocardiogram.\n",
    "    Values: 0 = Normal, 1 = ST-T wave abnormality, 2 = Probable or definite left ventricular hypertrophy\n",
    "\n",
    "8. Maximum Heart Rate Achieved (thalach): Maximum heart rate during examination.\n",
    "\n",
    "9. Exercise-Induced Angina (exang): Presence of exercise-induced angina.\n",
    "    Values: 1 = Yes, 0 = No\n",
    "\n",
    "10. ST Depression Induced by Exercise Relative to Rest (oldpeak): ST depression induced by exercise relative to rest.\n",
    "\n",
    "11. Slope of the Peak Exercise ST Segment (slope): Slope of the peak exercise ST segment.\n",
    "    Values: 1 = Upsloping, 2 = Flat, 3 = Downsloping\n",
    "\n",
    "12. Number of Major Vessels Colored by Fluoroscopy (ca): Number of major vessels colored by fluoroscopy. A higher count may indicate a greater degree of vessel involvement or narrowing, which can be associated with more advanced stages of coronary artery disease.\n",
    "\n",
    "13. Thalassemia (thal): Type of thalassemia.\n",
    "    Values: 3 = Normal, 6 = Fixed defect, 7 = Reversible defect\n",
    "\n",
    "14. Diagnosis of Heart Disease (num): Diagnosis based on angiographic disease status.\n",
    "    Values: 0 = < 50% diameter narrowing, 1 = > 50% diameter narrowing (in any major vessel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset information: \n",
    "https://archive.ics.uci.edu/dataset/45/heart+disease\n",
    "\n",
    "\n",
    "### 1.3 Introductory Paper\n",
    "\n",
    "International application of a new probability algorithm for the diagnosis of coronary artery disease.\n",
    "By R. Detrano, A. JÃ¡nosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, V. Froelicher. 1989\n",
    "\n",
    "Published in American Journal of Cardiology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Import Dataset and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "! pip install ucimlrepo\n",
    "! pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import shap\n",
    "\n",
    "# Define color palette for plot\n",
    "palette = [\"#87CEEB\", \"#FFA07A\"]\n",
    "\n",
    "# Silence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn._oldcore\",\n",
    "                        message=\"is_categorical_dtype is deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "heart_disease = fetch_ucirepo(name='Heart Disease')\n",
    "df = heart_disease['data']['original'] # access data\n",
    "\n",
    "# Print first 5 rows of our data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature Renaming\n",
    "\n",
    "To enhance interpretability and align with medical terminology, we will rename the columns using more descriptive names. This not only makes the dataset more understandable but also improves the overall clarity of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with the new column names\n",
    "new_column_names = {\n",
    "    'age': 'Age',\n",
    "    'sex': 'Sex',\n",
    "    'cp': 'ChestPainType',\n",
    "    'trestbps': 'RestingBloodPressure',\n",
    "    'chol': 'SerumCholesterol',\n",
    "    'fbs': 'FastingBloodSugar',\n",
    "    'restecg': 'RestingECG',\n",
    "    'thalach': 'MaxHeartRate',\n",
    "    'exang': 'ExerciseInducedAngina',\n",
    "    'oldpeak': 'STDepression',\n",
    "    'slope': 'SlopeSTSegment',\n",
    "    'ca': 'NumMajorVessels',\n",
    "    'thal': 'Thalassemia',\n",
    "    'num': 'HeartDiseaseDiagnosis'\n",
    "}\n",
    "\n",
    "# Rename the columns using the dictionary\n",
    "df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Print first 5 rows of our data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Target Binarization\n",
    "\n",
    "The target variable is binarized, simplifying the problem into a binary classification task. Values less than 1 are assigned 1 (positive diagnosis), while others are assigned 0 (negative diagnosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the distribution of the original target variable (`HeartDiseaseDiagnosis`) provides insights into the balance between positive and negative diagnoses.\n",
    "df['HeartDiseaseDiagnosis'].value_counts()\n",
    "\n",
    "# Binarize the target variable\n",
    "df['HeartDiseaseDiagnosis'] = np.int64(df['HeartDiseaseDiagnosis'] < 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution After Binarization\n",
    "\n",
    "Examining the distribution after binarization shows how the conversion has altered the balance between positive and negative diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"HeartDiseaseDiagnosis\", data=df, palette=palette)\n",
    "plt.xlabel(\"Heart Disease (0 = False, 1= True)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', data=df, palette=\"mako_r\")\n",
    "plt.xlabel(\"Sex (0 = female, 1= male)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Sex,df.HeartDiseaseDiagnosis).plot(kind=\"bar\",figsize=(15,6),color=palette)\n",
    "plt.title('Heart Disease Frequency for Sex')\n",
    "plt.xlabel('Sex (0 = Female, 1 = Male)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"Disease\", \"Not Disease\"])\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df.Age[df.HeartDiseaseDiagnosis==1], y=df.MaxHeartRate[(df.HeartDiseaseDiagnosis==1)], c=palette[1])\n",
    "plt.scatter(x=df.Age[df.HeartDiseaseDiagnosis==0], y=df.MaxHeartRate[(df.HeartDiseaseDiagnosis==0)], c=palette[0])\n",
    "plt.legend([\"Disease\", \"Not Disease\"])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Maximum Heart Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Categorical Encodingm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for each categorical variable\n",
    "ChestPainType_mapping = {1: 'Typical angina', 2: 'Atypical angina', 3: 'Non-anginal pain', 4: 'Asymptomatic'}\n",
    "Thalassemia_mapping = {3.0: 'Normal', 6.0: 'Fixed defect', 7.0: 'Reversible defect'}\n",
    "SlopeSTSegment_mapping = {1: 'Upsloping', 2: 'Flat', 3: 'Downsloping'}\n",
    "\n",
    "# Replace the values in the original DataFrame\n",
    "df['ChestPainType'] = df['ChestPainType'].map(ChestPainType_mapping)\n",
    "df['Thalassemia'] = df['Thalassemia'].map(Thalassemia_mapping)\n",
    "df['SlopeSTSegment'] = df['SlopeSTSegment'].map(SlopeSTSegment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.SlopeSTSegment,df.HeartDiseaseDiagnosis).plot(kind=\"bar\",figsize=(15,6),color=palette)\n",
    "plt.title('Heart Disease Frequency for Slope')\n",
    "plt.xlabel('The Slope of The Peak Exercise ST Segment ')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend([\"Not Disease\", \"Disease\"])\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.FastingBloodSugar,df.HeartDiseaseDiagnosis).plot(kind=\"bar\",figsize=(15,6),color=palette)\n",
    "plt.title('Heart Disease Frequency According To FBS')\n",
    "plt.xlabel('FBS - (Fasting Blood Sugar > 120 mg/dl) (1 = true; 0 = false)')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend([\"Not Disease\", \"Disease\"])\n",
    "plt.ylabel('Frequency of Disease or Not')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.ChestPainType,df.HeartDiseaseDiagnosis).plot(kind=\"bar\",figsize=(15,6),color=palette)\n",
    "plt.title('Heart Disease Frequency According To Chest Pain Type')\n",
    "plt.xlabel('Chest Pain Type')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend([\"Not Disease\", \"Disease\"])\n",
    "plt.ylabel('Frequency of Disease or Not')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Dummy Variables\n",
    "Since 'cp', 'thal' and 'slope' are categorical variables we'll turn them into dummy variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chest Pain Type (cp)**: Type of chest pain experienced.\n",
    "        Values: 1 = Typical angina, 2 = Atypical angina, 3 = Non-anginal pain, 4 = Asymptomatic\n",
    "\n",
    "**Thalassemia (thal)**: Type of thalassemia.\n",
    "        Values: 3 = Normal, 6 = Fixed defect, 7 = Reversible defect\n",
    "\n",
    "**Slope of the Peak Exercise ST Segment (slope)**: Slope of the peak exercise ST segment.\n",
    "        Values: 1 = Upsloping, 2 = Flat, 3 = Downsloping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to appropriate data types\n",
    "categorical_vars = ['ChestPainType', 'Thalassemia', 'SlopeSTSegment']\n",
    "df[categorical_vars] = df[categorical_vars].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('nan', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies and assign column names\n",
    "dummies = pd.get_dummies(df[categorical_vars], prefix=categorical_vars,dummy_na = False, drop_first=True).astype(np.int64)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "df = df.drop(columns=categorical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in all columns\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Display the count of missing values in each column\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "# Display the count of missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Preparation for Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate Features and Target Variable**\n",
    "\n",
    "The dataset is divided into features (X) and the target variable (y). Features (`X`) include all columns except for the target variable, while the target variable (`y`) is isolated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop('HeartDiseaseDiagnosis', axis=1)\n",
    "y = df['HeartDiseaseDiagnosis']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Hold-out Split**\n",
    "\n",
    "The dataset undergoes a hold-out split using train_test_split from scikit-learn. This partitions the data into training (X_train, y_train) and testing (X_test, y_test) sets, facilitating model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hold-out split (adjust test_size as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create and Train the Random Forest Model\n",
    "\n",
    "Instantiate a Random Forest classifier with the specified hyperparameters and train the model using the training data.\n",
    "Define hyperparameters for the Random Forest model. Students can experiment with and modify these values to observe their impact on model performance.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_depth**: Controls the maximum depth of each decision tree. A higher value captures more complex patterns but may lead to overfitting.\n",
    "\n",
    "**n_estimators**: Sets the number of decision trees in the Random Forest ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters (students can modify these)\n",
    "max_depth = 10\n",
    "n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Random Forest model\n",
    "model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
    "trained_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Model Evaluation and Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No Disease', 'Disease'], yticklabels=['No Disease', 'Disease'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Classification Report and ROC Curve\n",
    "\n",
    "Assess the model's classification performance using the classification report and visualize the Receiver Operating Characteristic (ROC) curve with the Area Under the Curve (AUC) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC (Area Under the Curve)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate (Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis and Interpretability\n",
    "\n",
    "Feature Importance Analysis involves understanding which factors have the most influence on a predictive model's decisions. In clinical practice, these factors may represent crucial patient parameters, biomarkers, or clinical indicators.\n",
    "\n",
    "**Importance in Clinical Practice**:\n",
    "- Reliability: Identifying influential features enhances the reliability of diagnostic or predictive models.\n",
    "- Interpretability: Knowing which factors matter most improves the interpretability of the model's decisions.\n",
    "- Clinical Relevance: Provides actionable insights for healthcare professionals to focus on key factors in patient assessment.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': trained_model.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importances with a bar plot using seaborn\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances, palette=\"viridis\")\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the reasonability of the feature importance analysis, let's conduct an exploratory analysis of the most relevant features. This additional investigation will provide insights into the patterns and characteristics of these features, helping us ensure their clinical relevance and alignment with our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NumMajorVessels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df['HeartDiseaseDiagnosis'], df['NumMajorVessels'])\n",
    "\n",
    "# Plot a stacked bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='NumMajorVessels', hue='HeartDiseaseDiagnosis', data=df, palette=palette)\n",
    "plt.title('Correlation Between Heart Disease Diagnosis and Number of Major Vessels')\n",
    "plt.xlabel('Heart Disease Diagnosis')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='HeartDiseaseDiagnosis', y='STDepression', data=df, palette=palette)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Heart Disease (0 = False, 1= True)')\n",
    "plt.ylabel('STDepression')\n",
    "plt.title('Box Plot of STDepression for Each Class')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2 Further Interpretability Analysis\n",
    "\n",
    "For a more in-depth validation, let's conduct further analysis using SHAP (SHapley Additive exPlanations). This approach will offer detailed insights into how each relevant feature contributes to individual model predictions, providing a robust understanding of the model's decision-making process and reinforcing the interpretability of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "# explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "patient_number = 2\n",
    "\n",
    "# Force plot with custom colors\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][patient_number], X_test.iloc[patient_number, :], plot_cmap=palette[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_number = np.argmin(y_probs)\n",
    "\n",
    "# Force plot with custom colors\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][patient_number], X_test.iloc[patient_number, :], plot_cmap=palette[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a beeswarm plot to visualize the impact of features on predictions.\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values[1], X_test, show=False)\n",
    "plt.title(\"SHAP Summary Plot - Impact on Heart Disease Diagnosis\")\n",
    "plt.xlabel(\"Impact on Model Output (Proximity to Heart Disease)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex (sex): Gender of the patient. Values: 1 = Male, 0 = Female\n",
    "\n",
    "Exercise-Induced Angina (exang): Presence of exercise-induced angina.\n",
    "    Values: 1 = Yes, 0 = No"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
